\documentclass[letterpaper]{article}
% Used to do math
\usepackage{amsmath}
\usepackage{amssymb}

% Used to color text (for todos)
\usepackage{xcolor}
% for when defining a new command to have to include a space at the end
\usepackage{xspace}
% for double space support
\usepackage{setspace}
\usepackage{mathrsfs}

% Used to embed pdfs from yEd and other sources
\usepackage{graphicx}
% Used to embed gnuplot output into document
\usepackage{epstopdf}
\usepackage{pdflscape}
\usepackage{geometry}

% For figures
\usepackage{float}
\usepackage{subfig}
\usepackage{wrapfig}

% packages for doing elaborate table stuff
\usepackage{array}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{tabularx}
% Used to have a table span multiple pages.
\usepackage{longtable}

% For writing pseudo code
\usepackage{algorithmicx}
\usepackage{algpseudocode}

% for code listings
\usepackage{listingsutf8}

% Deal with backwards quotes because evidently Latex doesn't know better.
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}

\newcommand{\TODO}[1]{\textcolor{red}{TODO: #1}}

\newcommand{\argmax}[1]{\underset{#1}{\text{argmax }}}
\newcommand{\cprob}[2]{ \prob{#1 \lvert #2} }
\newcommand{\prob}[1]{\mathbb{P}\left( #1 \right)}

\newgeometry{margin=1.125in}

\begin{document}

\title{Deep Learning for Automatic Speech Recognition}
\author{Ryan Hartsfield \and Garrett Lewellen}
\date{May 4, 2015}

\maketitle

\doublespacing

\section*{Introduction}

\paragraph{} In this paper we examine two deep learning method for automatic speech recognition: deep neural networks and convolutional neural networks based on the works of \cite{DBLP:journals/taslp/DahlYDA12} and  \cite{DBLP:journals/taslp/Abdel-HamidMJDPY14} respectively. \TODO{Ryan TODO}

\section*{Traditional Approach} \TODO{Ryan TODO}

\section*{Deep Neural Networks Approach} 

\paragraph{} In this section we discuss the work of \cite{DBLP:journals/taslp/DahlYDA12} consisting of a context dependent hidden markov model and deep neural network hybrid architecture (CD-HMM-DNN) for the acoustic model. We will begin with an overview of the general architecture, then explain the the general procedure for training, and conclude with discussion of the algorithms used for pre-training. Discussion of experimental results for this approach are deferred to the results section so that they can be compared to the convolutional neural network approach.

\subsection*{Architecture}

\paragraph{} To motivate their architecture, \cite{DBLP:journals/taslp/DahlYDA12} rely on the standard noisy channel model for speech recognition presented in \cite{jurafskyMartin} where we wish maximize the likelihood of a decoded word sequence given our input audio observations:

\begin{equation}
\hat{w} = \argmax{w \in \mathscr{L}} \cprob{w}{x} = \argmax{w \in \mathscr{L}} \cprob{x}{w} \prob{w} 
\label{eqn:asr:def}
\end{equation}

Where $\prob{w}$ and $\cprob{x}{w}$ represent the language and acoustic models respectively. \cite{jurafskyMartin} state that the language model can be computed via an N-gram approach, but \cite{DBLP:journals/taslp/DahlYDA12} do not state their method, instead the authors put their efforts into explaining their acoustic model:

\begin{equation}
\cprob{x}{w} = \sum_{q} \cprob{x,q}{w} \cprob{q}{w} \approxeq \max \pi(q_0) \prod_{t = 1}^T a_{q_{t-1} q_t} \prod_{t=0}^T \cprob{x_t}{q_t} 
\label{eqn:lm:def}
\end{equation}

Here the acoustic model is viewed as a sequence of transitions between states of tied-state triphones which \cite{DBLP:journals/taslp/DahlYDA12} refer to as senones \TODO{EXPLAIN WHAT SENONES ARE AND WHERE THEY COME FROM AND WHY THEY ARE USEFUL} which gives us the context dependent aspect of the architecture. The model assumes that there is a probability $\pi(q_0)$ for the starting state, probabilities $a_{q_{t-1} q_{t}}$ of transitioning to the state observed at step $t -1$ to step $t$, and finally, the probability of the acoustics given the current state $q_t$. \cite{DBLP:journals/taslp/DahlYDA12} expand this last term further into:

\begin{equation*}
	\cprob{x_t}{q_t} = \frac{\cprob{q_t}{x_t} \prob{x_t}}{\prob{q_t}}
	\label{eqn:senone:def}	
\end{equation*}

Where $\cprob{x_t}{q_t}$ models the tied triphone senone posterior given mel-frequency cepstral coefficients (MFCCs) based on 11 sampled frames of audio \TODO{EXPLAIN MFCCs AND WHY THEY ARE USEFUL}, $\prob{q_t}$ is the prior probability of the senone, and $\prob{x_t}$ can be ignored since it does not vary based on the decoded word sequence we are trying to find.

\paragraph{} Based on this formalism, \cite{DBLP:journals/taslp/DahlYDA12} chose to use pre-trained deep neural networks to estimate $\cprob{q_t}{x_t}$ using MFCCs as DNN inputs and taking the senone posterior probabilities as DNN outputs. The transitioning between events is bested modeled by hidden markov models whose notation, $\pi, a$, and $q$ appears in Eqn. (\ref{eqn:lm:def}). Now that we have an overview of the general CD-DNN-HMM architecture, we can look at how \cite{DBLP:journals/taslp/DahlYDA12} train their model.

\TODO{\begin{itemize}
	\item Include figure of architecture?
	\item \S 10.3 of \cite{jurafskyMartin} discusses Context-dependent Acoustic models: triphones
	\item \cite{DBLP:conf/interspeech/2014} talks about senone (tied-state triphones)
\end{itemize}}

\subsection*{Pre-Training}


\TODO{\begin{itemize}
	\item pre-training / contrastive divergence for RBM
	\item Hinton's method for DBN
\end{itemize}}


\subsection*{Training}

\paragraph{} Training of the CD-DNN-HMM model consists of roughly a dozen involved steps. We won't elaborate here on the full details of each step, but will instead provide a high-level sketch of the procedure to convey its general mechanics. 

\paragraph{} The first high-level step of the procedure is to initialize the CD-DNN-HMM model. This is done by first training a decision tree to find the best tying of triphone states which are then used to train a CD-GMM-HMM system. Next, the unique tied state triphones are each assigned a unique senone identifier. This mapping will then be used to label each of the tied state triphones. (These identifiers will be used later to refine the DNN.) Finally, the trained CD-GMM-HMM is converted into a CD-DNN-HMM by retaining the triphone and senone structure and HMM parameters. This resulting DNN goes through the pre-training procedure discussed in depth earlier. 

\paragraph{} The next high-level step iteratively refines the CD-DNN-HMM. To do this, first the originally trained CD-GMM-HMM model is used to generate a raw alignment of states \TODO{figure out what it's aligning to} which is then mapped to its corresponding senone identifier. This resulting alignment is then used to refine the DBN by backpropagation. Next, the prior senone probability is estimated based on the number of frames \TODO{elaborate more on these frames somewhere} paired with the senone and the total number of frames. These estimates are then used to refine the HMM transition probabilities to maximize the features. Finally, if this newly estimated parameters do not improve accuracy against a development set, then the training procedure terminates; otherwise, the procedure repeats this high-level step.

\paragraph{} \TODO{Discuss computational time to train}

\section*{Convolutional Neural Networks Approach} \TODO{Ryan TODO}

\section*{Experimental Results} 

\subsection*{System Configurations}

\paragraph{} \cite{DBLP:journals/taslp/DahlYDA12} report that their system relies on nationwide language model consisting of 1.5 million trigrams. For their acoustic model, then use a five hidden layer DNN with each layer containing 2,000 hidden units. 

\subsection*{Datasets}

\TODO{Garrett}

\subsection*{Results}

\begin{table}[H]
	\centering
	\begin{tabular}{c|c|c|c|c|c}
		& & \multicolumn{2}{c|}{Bing Mobile} & \multicolumn{2}{c}{TIMIT}\\
		& Architecture & Dev. & Test  & Dev. & Test \\
		\hline
		\multirow{2}{*}{Sentence Accuracy} & CD-GMM-HMMM & 70.3\% & 68.4\% & & \\
		& CD-DNN-HMM & 71.8\% & 69.6\% & & \\
		\hline
		Phone Error & CNN-HMM  & & &  & 20.07\%
	\end{tabular}
	\caption{Accuracy and error rates reported by \cite{DBLP:journals/taslp/DahlYDA12} and \cite{DBLP:journals/taslp/Abdel-HamidMJDPY14}.}
	\label{tbl:results}
\end{table}

\paragraph{} Direct comparison of the two systems is complicated by the fact that both papers report different metrics against different datasets. \cite{DBLP:journals/taslp/DahlYDA12} reports a sentence level accuracy rate, while \cite{DBLP:journals/taslp/Abdel-HamidMJDPY14} reports the phone error rate.


\section*{Conclusions} \TODO{Garrett TODO}

\appendix

\singlespacing

\bibliographystyle{alpha}
\bibliography{references}

\end{document}